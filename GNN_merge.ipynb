{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_wrn_ebm as train\n",
    "import argparse\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.datasets import TUDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--n_valid'], dest='n_valid', nargs=None, const=None, default=5000, type=<class 'int'>, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(\"Energy Based Models and Shit\")\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"cifar10\", choices=[\"cifar10\", \"svhn\", \"cifar100\"])\n",
    "parser.add_argument(\"--data_root\", type=str, default=\"log_out\")\n",
    "\n",
    "# optimization\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "parser.add_argument(\"--decay_epochs\", nargs=\"+\", type=int, default=[160, 180],\n",
    "                    help=\"decay learning rate by decay_rate at these epochs\")\n",
    "parser.add_argument(\"--decay_rate\", type=float, default=.3,\n",
    "                    help=\"learning rate decay multiplier\")\n",
    "parser.add_argument(\"--clf_only\", action=\"store_true\", help=\"If set, then only train the classifier\")\n",
    "parser.add_argument(\"--labels_per_class\", type=int, default=-1,\n",
    "                    help=\"number of labeled examples per class, if zero then use all labels\")\n",
    "parser.add_argument(\"--optimizer\", choices=[\"adam\", \"sgd\"], default=\"adam\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=200)\n",
    "parser.add_argument(\"--warmup_iters\", type=int, default=-1,\n",
    "                    help=\"number of iters to linearly increase learning rate, if -1 then no warmmup\")\n",
    "# loss weighting\n",
    "parser.add_argument(\"--p_x_weight\", type=float, default=1.)\n",
    "parser.add_argument(\"--p_y_given_x_weight\", type=float, default=1.)\n",
    "parser.add_argument(\"--p_x_y_weight\", type=float, default=0.)\n",
    "# regularization\n",
    "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
    "parser.add_argument(\"--sigma\", type=float, default=3e-2,\n",
    "                    help=\"stddev of gaussian noise to add to input, .03 works but .1 is more stable\")\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
    "# network\n",
    "parser.add_argument(\"--norm\", type=str, default=None, choices=[None, \"norm\", \"batch\", \"instance\", \"layer\", \"act\"],\n",
    "                    help=\"norm to add to weights, none works fine\")\n",
    "# EBM specific\n",
    "parser.add_argument(\"--n_steps\", type=int, default=20,\n",
    "                    help=\"number of steps of SGLD per iteration, 100 works for short-run, 20 works for PCD\")\n",
    "parser.add_argument(\"--width\", type=int, default=10, help=\"WRN width parameter\")\n",
    "parser.add_argument(\"--depth\", type=int, default=28, help=\"WRN depth parameter\")\n",
    "parser.add_argument(\"--uncond\", action=\"store_true\", help=\"If set, then the EBM is unconditional\")\n",
    "parser.add_argument(\"--class_cond_p_x_sample\", action=\"store_true\",\n",
    "                    help=\"If set we sample from p(y)p(x|y), othewise sample from p(x),\"\n",
    "                            \"Sample quality higher if set, but classification accuracy better if not.\")\n",
    "parser.add_argument(\"--buffer_size\", type=int, default=10000)\n",
    "parser.add_argument(\"--reinit_freq\", type=float, default=.05)\n",
    "parser.add_argument(\"--sgld_lr\", type=float, default=1.0)\n",
    "parser.add_argument(\"--sgld_std\", type=float, default=1e-2)\n",
    "# logging + evaluation\n",
    "parser.add_argument(\"--save_dir\", type=str, default='./experiment')\n",
    "parser.add_argument(\"--ckpt_every\", type=int, default=10, help=\"Epochs between checkpoint save\")\n",
    "parser.add_argument(\"--eval_every\", type=int, default=1, help=\"Epochs between evaluation\")\n",
    "parser.add_argument(\"--print_every\", type=int, default=100, help=\"Iterations between print\")\n",
    "parser.add_argument(\"--load_path\", type=str, default=None)\n",
    "parser.add_argument(\"--print_to_log\", action=\"store_true\", help=\"If true, directs std-out to log file\")\n",
    "parser.add_argument(\"--plot_cond\", action=\"store_true\", help=\"If set, save class-conditional samples\")\n",
    "parser.add_argument(\"--plot_uncond\", action=\"store_true\", help=\"If set, save unconditional samples\")\n",
    "parser.add_argument(\"--n_valid\", type=int, default=5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root = \"molecule_dataset\", name = \"MUTAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "maxNodes = 0\n",
    "for i in range(len(dataset)):\n",
    "    n = dataset[i].num_nodes\n",
    "    if (n > maxNodes):\n",
    "        maxNodes = n\n",
    "\n",
    "print(maxNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[ 0,  0,  1,  1,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  6,  6,  7,  7,\n",
       "          8,  8,  8,  9,  9,  9, 10, 10, 11, 11, 12, 12, 12, 13, 13, 14, 14, 14,\n",
       "         15, 16],\n",
       "        [ 1,  5,  0,  2,  1,  3,  2,  4,  9,  3,  5,  6,  0,  4,  4,  7,  6,  8,\n",
       "          7,  9, 13,  3,  8, 10,  9, 11, 10, 12, 11, 13, 14,  8, 12, 12, 15, 16,\n",
       "         14, 14]]), 'x': tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0.]]), 'edge_attr': tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.]]), 'y': tensor([1])}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testMol = dataset[0]\n",
    "s = testMol.edge_stores[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 38])\n",
      "torch.Size([17, 7])\n",
      "torch.Size([38, 4])\n"
     ]
    }
   ],
   "source": [
    "print(s['edge_index'].size())   # 2 x E edges\n",
    "print(s['x'].size())            # N nodes x 7 node features\n",
    "print(s['edge_attr'].size())    #E edges X 4 edge features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOAL:\n",
    "1) create ordered map of (edge_type, vector_idx)\n",
    "2) create function to use map to identify vector location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_map = dict()\n",
    "\n",
    "pos_ctr = 0\n",
    "for i in range(28):\n",
    "    for j in range(i):\n",
    "        vector_map[(j, i)] = pos_ctr\n",
    "        pos_ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "args.n_classes = 100 if args.dataset == \"cifar100\" else 10\n",
    "train.main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
